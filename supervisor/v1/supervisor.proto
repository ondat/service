syntax = "proto3";
package supervisor.v1;
option go_package = "code.storageos.net/storageos/service/supervisor/v1";

import "common.proto";
import "filesystem.proto";
import "rdbplugin.proto";
import "directfs.proto";
import "director.proto";

/**
 * Director configuration and status service.
 */
service Supervisor {
    /**
     * Get program status.
     */
    rpc Status(SupervisorStatusRequest) returns (SupervisorStatus) {}

    /**
     * Reap a volume.
     */
    rpc ReapVolume(ReapVolumeRequest) returns (ReapVolumeResponse) {}

    /**
     * Delete a mapping, freeing associated resources.
     */
    rpc DeleteMapping(DeleteMappingRequest) returns (DeleteMappingResponse) {}

    /**
     * Perform actions that really only make sense for very low-level testing.
     */
    rpc Poke(common.v1.PokeQuery) returns (common.v1.PokeResponse) {}

    // Config services, from common.v1.
    rpc ConfigGetBool(common.v1.ConfigKey) returns (common.v1.ConfigGetBoolReply) {}
    rpc ConfigUpdateBool(common.v1.ConfigBool) returns (common.v1.ConfigUpdateReply) {}
    rpc ConfigListBool(common.v1.ConfigListQuery) returns (common.v1.ConfigBoolList) {}

    rpc ConfigGetString(common.v1.ConfigKey) returns (common.v1.ConfigGetStringReply) {}
    rpc ConfigUpdateString(common.v1.ConfigString) returns (common.v1.ConfigUpdateReply) {}
    rpc ConfigListString(common.v1.ConfigListQuery) returns (common.v1.ConfigStringList) {}

    rpc ConfigGetUint32(common.v1.ConfigKey) returns (common.v1.ConfigGetUint32Reply) {}
    rpc ConfigUpdateUint32(common.v1.ConfigUint32) returns (common.v1.ConfigUpdateReply) {}
    rpc ConfigListUint32(common.v1.ConfigListQuery) returns (common.v1.ConfigUint32List) {}

    rpc ConfigGetUint64(common.v1.ConfigKey) returns (common.v1.ConfigGetUint64Reply) {}
    rpc ConfigUpdateUint64(common.v1.ConfigUint64) returns (common.v1.ConfigUpdateReply) {}
    rpc ConfigListUint64(common.v1.ConfigListQuery) returns (common.v1.ConfigUint64List) {}

    /**
     * Sync the specified regions. Called by symmetra.
     */
    rpc SyncRegions(SyncRegionsRequest) returns (SyncRegionsResponse) {}

    /**
     * Return a hash list for the specified volume, over the specified range.
     * Note: this is a streaming RPC as the hash lists returned could conceiveably
     * be multiple megabytes in size.
     *
     * returns the hash list and volume hash
     */
    rpc VolumeHashList(VolumeHashListRequest) returns (stream VolumeHashListResponse) {}

    /**
     ** Sync 2020.1 consumer count interface.
     **/
    rpc GetVolumeConsumerCount(GetVolumeConsumerCountRequest) returns (GetVolumeConsumerCountReply) {}
    rpc SetVolumeConsumerCount(SetVolumeConsumerCountRequest) returns (SetVolumeConsumerCountReply) {}

    /**
     * Collect the dataplane node-level metrics and specific per-volume metrics.
     * NOTE: This is an experimental dataplane-only API. It's probably not quite
     * what the control-plane requires in terms of a metrics API, but it's fine
     * for dataplane tooling and tests.
     */
    rpc Metrics(MetricsRequest) returns (MetricsResponse) {}

    /**
     * Interface to dump all the configurations from the dataplane
     */
    rpc DumpConfig(DumpConfigRequest) returns (DumpConfigResponse) {}
}

message ReapVolumeRequest {
    string uuid = 1;
    uint32 inode = 2;
}

message ReapVolumeResponse {
    // Empty for now
}

message DeleteMappingRequest {
    string uuid = 1;
}

message DeleteMappingResponse {
    // Empty for now.
}

message SupervisorStatusRequest {
    // Empty for now.
}

message SupervisorStatus {
    // Generic daemon status.
    common.v1.DaemonStatus status = 2;

    // Composite Id Mapper status.
    IdMapperStatus idmap_status = 3;

    // Composite consumer count status.
    ConsumerCountStatus cc_status = 4;
}

/**
 ** Id Mapper status.
 **/

message IdMapping {
    string uuid = 1;
    uint32 inode = 2;
}

message IdMapperStatus {
    enum MapMode {
        NOTSET = 0;  // No value (new dataplane, never been configured).
        GSI = 1;     // Global-scope inodes (v1).
        NLI = 2;     // Node-local inodes (v2).
    };

    // The map mode, only valid if mode_set==true.
    MapMode mode = 2;

    // A list of mappings.
    repeated IdMapping mappings = 3;
}

/**
 ** Consumer count storage status.
 **/

message ConsumerCountStatus {
    // Just a list of counts and mappings.
    repeated ConsumerCountEntry ccs = 1;
}

message ConsumerCountEntry {
    // The mapping for which we're returning a CC.
    IdMapping mapping = 1;
    // The cc for the provided mapping.
    common.v1.ConsumerCount cc = 2;
}

/**
 ** Volume hash lists (sync).
 **/

// Syncing a volume is a multi stage process:
//
// * first the CP invokes symmetra (a standalone binary), which then
// * calls the VolumeHashList() RPC for the master and replica deployments
// * symmetra then calls the Sync() RPC multiple times on the master to copy the data
//
// We want to be able to track this transaction across it's entire duration.
// The SyncContext message type allows us to do this. When symmetra is first
// invoked it generates the SyncContext. This token is then passed in all subsequent
// VolumeHashListRequests and SyncRegionRequests. Any code taking part in
// the sync operation can then log this ID as part of any structued logging calls.
//
// UUIDs seem to be in fashion at the moment so we'll use that as the unique identifier.
message SyncContext {
    string uuid = 1;
}

message VolumeHash {
    // There's no way to define this in the proto but bytes.size() is always
    // sizeof(HashType_t). Currently 16 bytes.
    bytes bytes = 1;
}

enum VolumeHashListRpcVersion {
    V1 = 0;  // < Storageos v2.4.0
    V2 = 1;  // >= Storageos v2.4.0: in this verison we make the change outlined in
             // https://docs.google.com/document/d/1t1_LBSl0XXcT1VNpaCZpn_7I4UAHYpgmtBIEWNrj8mI
             // Appendix-3. To summarise: we now treat thinly provisioned blocks
             // as disticint special values with a block hash of kThinProvBlockHash
             // rather than materialising a block of zeros, applying the necessary
             // encoding and then taking the block hash. This is required for encrypted
             // sync and snapshto sync. The VolumeHashListRpcVersion enum was only
             // added in Storageos v2.4.0, so VolumeHashListRequest and VolumeHashListResponse
             // messages prior to this implicitly have the default value of V1.
}

// Note: the response to this message, VolumeHashListResponse, is chunked
// (streamed in gRPC parlance).
message VolumeHashListRequest {
    // See the VolumeHashListRpcVersion documentation
    VolumeHashListRpcVersion version = 7;

    // The volume we want to generate a hash over
    uint32 volume_id = 1;

    // The volume UUID we want to generate a hash over.
    string volume_uuid = 5;

    // Defines the byte offset into `volume_id` at which we'll start hash list
    // generation.
    uint64 start_offset = 2;

    // Defines the byte offset into `volume_id` at which we'll end hash list
    // generation.
    uint64 end_offset = 3;

    // When generating the hash list we do so by rolling together individual block
    // hashes into a region hash. This field defines the size of that region in
    // bytes. It must be multiple of RIXIO_BSIZE. By giving the option for clients
    // to specify this size they can optimise based on volume size and required
    // sync granularity.
    uint64 region_size = 4;

    // As it stands we need to know if the volume is compressed or not in order to
    // generate the volume hashes. This field will likely become redundant once
    // DP-40 is fixed.
    bool is_compressed = 6;

    // The SyncContext, initially generated by symmetra, associated with the over-arching sync operation
    // This field is purely used for logging, so there's no harm in not setting it in test code
    SyncContext sync_context = 8;
}

// This message is streamed back to the client in response to a
// VolumeHashListRequest message. As such the client should expect to receive
// many of these messages. Each VolumeHashListResponse contains the hash list
// for a sequential portion of the volume. For simplicity the volume_hash -- i.e
// the hash for the range [start_offset, end_offset) as specified in the initial
// VolumeHashListRequest
// -- is stored in every message.
message VolumeHashListResponse {
    // See the VolumeHashListRpcVersion documentation
    VolumeHashListRpcVersion version = 5;

    // The hash over the region [start_offset, end_offset) as specified in the
    // initial VolumeHashListRequest
    VolumeHash volume_hash = 1;

    // Defines the byte offset into `volume_id` at which hash_list[0] begins.
    uint64 start_offset = 2;

    // Defines the byte offset into `volume_id` at which hash_list[max] ends.
    uint64 end_offset = 3;

    // A list of region hashes pertaining to the regions defined by the byte range
    // [start_offset, end_offset). The number of regions depends on the
    // `region_size` defined in the inital VolumeHashListRequest.
    repeated VolumeHash hash_list = 4;
}

message GetVolumeConsumerCountRequest {
    // The UUID whose consumer count we are requesting.
    string uuid = 1;

    // The inode whos consumer count we are requesting.
    uint32 inode = 2;
}

message GetVolumeConsumerCountReply {
    // The UUID we're returning the cc for.
    string uuid = 1;

    // The inode whos consumer count we are requesting.
    uint32 inode = 3;

    // The Consumer Count for this uuid.
    common.v1.ConsumerCount cc = 2;
}

message SetVolumeConsumerCountRequest {
    // The UUID whose consumer count is being set.
    string uuid = 1;
    // The inode whos consumer count is being set.
    uint32 inode = 3;
    // The Consumer Count being set.
    common.v1.ConsumerCount cc = 2;
}

message SetVolumeConsumerCountReply {
    // The UUID whose consumer count was set.
    string uuid = 1;
    // The inode whos consumer count was set.
    uint32 inode = 3;
    // The Consumer Count returned by the data plane on attempting to set the
    // value contained in the SetVolumeConsumerCountRequest. May be >=
    // request.cc.
    common.v1.ConsumerCount cc = 2;
}

/*
 * Metrics
 */
enum MetricType {
    // Counters may only increase (like an odometer)
    COUNT = 0;

    // Gauges may fluctuate (like a speedometer)
    GAUGE = 1;
}

message Metric {
    // The metric name
    string name = 1;

    // Counter or gauge
    MetricType type = 2;

    // Instantaneous value
    uint64 value = 3;
}

message MetricsRequest {
    // A list of volumes to query (by inode). If this and uuids is left empty we'll return
    // metrics for all volumes which are configured.
    repeated uint32 inodes = 1;

    // A list of volume to query (by uuid). If this and uuids is left empty we'll return
    // metrircs for all volumes which are configured.
    repeated string uuids = 2;
}

message VolumeMetrics {
    // The volume this collection of metrics belongs to
    uint32 inode = 1;

    // The volume this collection of metrics belongs to
    string uuid = 2;

    repeated Metric metrics = 3;
}

// Node-level metrics are metrics which aren't specific to a volume.
message NodeMetrics {
    repeated Metric metrics = 1;
}

message MetricsResponse {
    // Per volume stats. One collection of metrics per requested volume.
    repeated VolumeMetrics volume_metrics = 1;

    // Per node stats. One collection per node.
    NodeMetrics node_metrics = 2;
}

message DumpConfigRequest {}

message DumpConfigResponse {
    // fsctl pr list
    filesystem.v1.FsPresentationList fs_presentation_list = 1;
    // fsctl vol list
    filesystem.v1.FsVolumeList fs_volume_list = 2;
    // dirctl pr list
    director.v1.DirectorPresentationList director_presentation_list = 3;
    // dirctl vol list
    director.v1.DirectorVolumeList director_volume_list = 4;
    // dfsictl vol list
    directfs.v1.DfsInitiatorVolumeList dfs_initiator_volume_list = 5;
    // dfsictl node list
    directfs.v1.DfsInitiatorNodeList dfs_initiator_node_list = 6;
    // rdbctl vol list
    rdbplugin.v1.RdbVolumeList rdb_volume_list = 7;
    // supctl status
    SupervisorStatus supervisor_status = 8;
}

message SyncRegion {
    uint64 start_offset = 1;
    uint64 end_offset = 2;
}

message SyncRegionsRequest {
    // The source volume ID.
    uint32 source_volume = 1;

    // The source UUID.
    // This field is used as the volume identifier over destination_volume if
    // destination_volume is set to INVALID_INODE;
    string source_uuid = 2;

    // The destination volume ID.
    uint32 destination_volume = 3;

    // The destination UUID.
    // This field is used as the volume identifier over destination_volume if
    // destination_volume is set to INVALID_INODE;
    string destination_uuid = 4;

    // The regions to sync
    repeated SyncRegion regions = 5;

    // Whether the sync should be forced. If this flag is set we'll overwrite
    // every sync block transaction ID with TransactionId{node_cc, 0}, where
    // node_cc is the consumer count of the source volume. See sync2020.pdf for
    // the rationale behind this.
    bool force = 6;

    // The SyncContext, initially generated by symmetra, associated with the over-arching sync operation
    // This field is purely used for logging, so there's no harm in not setting it in test code
    SyncContext sync_context = 7;

    // If set we'll wait for the network connection between the sync source (the primary)
    // and the sync target (the replica) to establish before trying to sync any data.
    // If the network connection never establishes then we'll fail the operation. We'll
    // wait for up to 1.5 times the directfs initiator reconnection interval before giving
    // up.
    //
    // This feature was added as a result of DP-280 and addresses the problem where the CP
    // configures the directfs initiator connection and starts the sync operation before
    // the connection is established. Something like this:
    // 1. CP configures connection from node A to node B
    // 2. Node B reboots
    // 3. Node A sits there in a retry loop trying to re-establish connection A -> B,
    //    this happens every 5 seconds CP runs symmetra.
    // 4. The hash list generation succeeds on node A and node B in couple of milliseconds
    // 5. Symmetra start's syncing data, and fails immediately as we still don't have an
    //    established connection between A and B
    // 6. Eventually connection A -> B succeeds
    // 7. CP throws away the replica because the sync fails
    //
    // The intention is that this boolean will be set true for the first SyncRegionsRequest
    // sent by symmetra for a given sync operation. All subsequent requests will set the
    // boolean to false - we don't want to stall the sync process by continually waiting
    // for a flappy network.
    bool wait_for_connection_established = 8;
}

message SyncRegionsResponse {
    // Whether or not the operation was successful.
    bool success = 1;

    // If the operation was not successful, this is an explanatory message as to
    // why.
    string reason = 2;
}
