syntax = "proto3";
package supervisor.v1;
option go_package = "code.storageos.net/storageos/service/supervisor/v1";

import "common.proto";

// The type of the deployment.
enum DeploymentType {
    UNKNOWN = 0;
    MASTER = 1;
    REPLICA = 2;
}

message NodeConfig {
    // The remote peer's UUID
    string uuid = 1;

    // The hostname of the remote peer
    string hostname = 2;

    // The port of the remote peer normally 5703 (can be overriden by starting
    // the Dataplane with IO_BIND_PORT=<port>)
    uint32 port = 3;

    // Whether TLS is enabled for this connection (always true when the CP is
    // managing the DP).
    bool tls_enabled = 4;

    // This field specifies the hostname to use when performing rfc2818
    // hostname verification of the remote end. If this field is empty
    // we use the dial address, i.e. `hostname`. With out current PKI
    // infrastructure this field should always be set by the CP as the
    // `hostname`, will never match the server Common Name in the server's
    // certificate
    optional string opt_verify_hostname = 5;
}

message DeploymentConfig {
    // Wraps a replica and its location
    message ReplicaAndLocation {
        // The replica deployment's UUID
        string uuid = 1;

        // In practice this must always be present when the Dataplane is being
        // managed by the CP. There's no such thing as a local replica in
        // production. For the purpose of DP testing this feild can be empty,
        // which signifies the replica is local to the master
        optional NodeConfig opt_node_config = 2;
    }

    // Is this a master or a replica?
    DeploymentType deployment_type = 1;

    // The deployment's UUID
    string uuid = 2;

    // Whether the deployment uses compression. In reality this is a per volume
    // option. All deployments should use compression if the volume uses
    // compression. This field is also sticky, you can't choose to undo at a
    // later date. Compression is applied to the underlying block data which
    // is stored in the blob files. Normally we recommend disabling compression.
    bool uses_compression = 3;

    // The consumer count for the volume.
    common.v1.ConsumerCount cc = 4;

    // The replicas associated with this deployment. This field is only
    // valid if the deployment is a master deployment.
    repeated ReplicaAndLocation replicas = 5;
}

message PresentationConfig {
    // The volume that this presentation pertains to. This is used by the dataplane
    // to decorate log messages with "volume_id=...". In the past we just used the
    // presentation_uuid as this field. Now that we have snapshot volumes, which are
    // in the form <parent_vol_id>/<snap_vol_id> we need a way to pass this field explicitly.
    string volume_id = 10;

    // A unique identifier for the presentation. There's no good reason why this should
    // be anything other than the UUID of the volume. For snapshot volumes, which
    // are in the form <parent_vol_id>/<snap_vol_id>. This should be the <snap_vol_id>
    string presentation_uuid = 1;

    // The filename of the block device we'll create for the volume under
    // /var/lib/storageos/volumes. Historically v.<volume_uuid>. Calling it
    // anything else will make debugging a nightmare.
    string filename = 2;

    // The deployment we are presenting (always the master deployment).
    string deployment_uuid = 3;

    // The size of the volume in bytes
    uint64 size = 4;

    // Even though compression is applied on the deployments at the point where we we store
    // the blocks we need to know whether we are using compression when configuring the
    // presentation. This is because we disallow UNMAP support on block devices which are backing
    // compressed volumes (for performance reasons).
    bool uses_compression = 5;

    // The consumer count of the volume
    common.v1.ConsumerCount cc = 6;

    // Only present if the volume's master is on a remote node
    optional NodeConfig opt_node_config = 7;

    // If the volume is using encryption then the crypo parameters should be
    // specified here. Once we've started using encryption on a volume it's
    // impossible to undo it. The opposite is also true.
    optional common.v1.VolumeCrypto opt_volume_crypto = 8;

    // If this field is set it denotes that we are presenting a snapshot. Snapshot
    // presentations are read-only.
    optional uint64 opt_snapshot_id = 9;
}

message PresentationScsiDevice {
    // This object could easily contain a bunch of other details about the
    // created scsi device, e.g. the /sys filesystem LUN path, the HBA path,
    // etc. Just ask.

    // The host block device major number.
    uint32 major = 1;
    // The host block device minor number.
    uint32 minor = 2;
}

// The primary job of the Supervisor service is to expose the RPCs necessary
// to configure volumes in the dataplane. A volume is the collection of the
// following entities:
//
// 1. a master deployment
// 2. zero or more replica deployments.
// 3. (optional) a presentation, which can be used to access the volume. The
//    presentation may be local or remote.
//
// The diagram below shows on which node certain RPCs may be called:
//
//  ConfigurePresentation()
//  ConfigurePresentation()
//  DeconfigurePresentation()
//          |
//          |
//          |
//  +-------v-------+           +---------------+            +---------------+
//  |               |           |               |            |               |
//  |  Attach Node  |           |               |            |               |
//  | (may be the   |---------->|  Master Node  |----------->| Replica Node  |
//  | master node)  |           |               |            |               |
//  |               |           |               |            |               |
//  +---------------+           +---------------+            +---------------+
//         \                            /\                             /
//          \--- SetConsumerCount()--- /  \ --- DeleteDeployment() ---/
//                                            ConfigureDeployment()
//                                            DeconfigureDeployment()
//
service Supervisor {
    // Query the status of the dataplane. At the moment there's nothing actually interesting in the
    // response type. Simply calling this RPC and receiving a response denotes that the dataplane is
    // up and running an ready to service RPCs. This API comes in useful in scripts which want to
    // poll until the dataplane is ready (for example in the DPLL systemd scripts) and in contexts
    // where we want to explicitly check the network connection to the DP (for example in Symmetra).
    // Note: there's some overlap in functionality with the dataplane Event server, which sends
    // EventDataplaneStartupFinished and EventDataplaneShutdownComplete messages on startup and
    // shutdown respectively. The CP should favour using the event server API to ascertain when the
    // dataplane is started and ready to receive RPC requests.
    rpc Status(StatusRequest) returns (StatusResponse) {}

    // ----------------- CONFIGURATIONS RPCS -------------------------------
    // Creates deployment. Either a master or a replica. The CP should signals
    // which by setting the `deployment_type` field within the DeploymentConfig
    // message type. Like all "Configure*" RPCs this method has "create if not
    // present, else update" semantics, i.e.:
    //
    //  - if no configuration exists for "uuid" we create the deployment
    //  - if configuration exists for "uuid" then we overwrite the current config.
    //
    // Creates will be rejected if: the CP tries to configure a replica deployment
    // which has replicas; the consumer count is zero.
    //
    // Overwites will be rejected if: the consumer count is decremented or the
    // compression flag has changed. Once specified compression can not be modified.
    //
    // Under the hood this method creates the blob files into which we'll store
    // user data and sets up the network connection to any replicas (master
    // deployments only).
    //
    // Note: this RPC does not configure the replicas it merely tells the
    // master about the existance and location of its replicas. To configure
    // the replicas call ConfigureReplica on the appropriate replica nodes,
    // prior to this call.
    //
    // On success rpc_result.success will be set to true. On failure it will
    // be set to false and rpc_result.code will be set to STATUS_*.
    // rpc_result.reason may be set.
    rpc ConfigureDeployment(ConfigureDeploymentRequest) returns (ConfigureDeploymentResponse) {}

    // Deconfigure the deployment. This lets the dataplane know that we are done
    // with the deployment and allows the dataplane to release runtime resources
    // associated with the deployment. The CP would typically call this API when
    // a the volume is no longer in use.
    //
    // This RPC does not delete the block (meta)data associated with the
    // deployment. Call DeleteDeployment for that.
    //
    // On success rpc_result.success will be set to true. On failure it will be
    // set to false and rpc_result.code will be set accordingly. The only specific
    // code returned is STATUS_NOT_FOUND - this is set when the deployment you
    // asked to deconfigure is not configured. For all other errors rpc_result.code
    // will be set to STATUS_*. In all failure case rpc_result.reason may be set.
    rpc DeconfigureDeployment(DeconfigureDeploymentRequest)
        returns (DeconfigureDeploymentResponse) {}

    // Irrevocably delete the deployment (meta)data.
    //
    // The deployment must be deconfigured, via DeconfigureDeployment, prior
    // to calling this method, or we'll reject the request with an error.
    //
    // On success rpc_result.success will be set to true. On failure it will be
    // set to false and rpc_result.code will be set accordingly. The only specific
    // code returned is STATUS_NOT_FOUND - this is set when the deployment you
    // asked to delete does no exist. For all other errors rpc_result.code will be
    // set to STATUS_*. In all failure case rpc_result.reason may be set.
    rpc DeleteDeployment(DeleteDeploymentRequest) returns (DeleteDeploymentResponse) {}

    // Configure a presentation. This creates a block device which can be used
    // to access the volume. This RPC works for both local and remote
    // presentations. Like all "Configure*" RPCs this method has "create if not
    // present, else update" semantics, i.e.:
    //
    //  - if no configuration exists for "presentation_uuid" then create the
    //  presentation
    //  - if a presentation exists for "presentation_uuid" then apply any diffs
    //    against the existing config. Valid diffs include: increasing the
    //    volume size, changing the target deployment (useful during a fail
    //    over); and increasing the consumer count. It's not permitted to change
    //    the crypto config for obvious reasons.
    //
    // On success rpc_result.success will be set to true. On failure it will
    // be set to false and rpc_result.code will be set to STATUS_*.
    // rpc_result.reason may be set.
    rpc ConfigurePresentation(ConfigurePresentationRequest)
        returns (ConfigurePresentationResponse) {}

    // Delete a previous created presentation
    //
    // On success rpc_result.success will be set to true. On failure it will
    // be set to false and rpc_result.code will be set accordingly. The only
    // specific code returned is STATUS_NOT_FOUND - this is set when the
    // presentation you asked to delete doesn't even exist. For all other errors
    // rpc_result.code will be set to STATUS_*. In all failure case
    // rpc_result.reason may be set.
    rpc DeconfigurePresentation(DeconfigurePresentationRequest)
        returns (DeconfigurePresentationResponse) {}

    // Create a snapshot of a deployment. This API must only be called for the volume's
    // master deployment and on the node which houses said deployment. The user must
    // provide a per-deployment-unique 64bit snapshot ID in the CreateSnapshotRequest.
    // This ID is used, along with the master deployment ID, to uniquely identify the
    // snapshot in subsequent ConfigurePresentation, DeconfigurePresentation, ListSnapshots
    // and ReapSnapshot RPCs. Snapshots can only be accessed by configuring a presentation
    // and supplying the `opt_snapshot_id` field. Snapshots may only be accessed read-only.
    //
    // On success rpc_result.success will be set to true. On failure it will
    // be set to false and rpc_result.code will be set to STATUS_*.
    // rpc_result.reason may be set.
    rpc CreateSnapshot(CreateSnapshotRequest) returns (CreateSnapshotResponse) {}

    // Delete a snapshot of a deployment. This API must only be called for the volume's
    // master deployment and on the node which houses said deployment. The user must
    // specify the snapshot ID, which was provided in the previous CreateSnapshot RPC.
    //
    // On success rpc_result.success will be set to true. On failure it will be
    // set to false and rpc_result.code will be set accordingly. The only specific
    // code returned is STATUS_NOT_FOUND - this is set when the deployment you
    // asked to deconfigure is not configured. For all other errors rpc_result.code
    // will be set to STATUS_*. In all failure case rpc_result.reason may be set.
    rpc ReapSnapshot(ReapSnapshotRequest) returns (ReapSnapshotResponse) {}

    // List all snapshots which exist for for a given deployment.
    rpc ListSnapshots(ListSnapshotsRequest) returns (ListSnapshotsResponse) {}

    // Set the consumer count for a deployment. This should only ever be called
    // on the master deployment (we don't ever need to set the consumer count
    // on a replica). The CP only needs to call this API when it wants to
    // explicitly change the consumer count. The only time I believe this is
    // currently necessary is during a failover. Normally the consumer count value
    // is implicitly transmitted to the dataplane by calling ConfigureDeployment. The
    // ConfigureDeployment request contains the consumer count.
    //
    // On success rpc_result.success will be set to true. On failure it will
    // be set to false and rpc_result.code will be set accordingly. The only
    // specific code returned is STATUS_NOT_FOUND - this is set when the
    // master you asked to set the CC on doesn't even exist. For all other
    // errors rpc_result.code will be set to STATUS_*. In all failure case
    // rpc_result.reason may be set. If the consumer count which was requested
    // to be set is LOWER than the currently set value then this method will
    // set rpc_result.success to true. The actual value of the consumer count
    // - i.e. the current, higher value - will be returned in the response.
    rpc SetConsumerCount(SetConsumerCountRequest) returns (SetConsumerCountResponse) {}

    // Get the consumer count for a given deployment
    //
    // Returns STATUS_NOT_FOUND if the deployment does not exist.
    // Returns STATUS_* for any other errors
    rpc GetConsumerCount(GetConsumerCountRequest) returns (GetConsumerCountResponse) {}

    // Dump the dataplane's current configuration
    rpc DumpConfig(DumpConfigRequest) returns (DumpConfigResponse) {}

    // Config services, from common.v1.
    rpc ConfigGetBool(common.v1.ConfigKey) returns (common.v1.ConfigGetBoolReply) {}
    rpc ConfigUpdateBool(common.v1.ConfigBool) returns (common.v1.ConfigUpdateReply) {}
    rpc ConfigListBool(common.v1.ConfigListQuery) returns (common.v1.ConfigBoolList) {}

    rpc ConfigGetString(common.v1.ConfigKey) returns (common.v1.ConfigGetStringReply) {}
    rpc ConfigUpdateString(common.v1.ConfigString) returns (common.v1.ConfigUpdateReply) {}
    rpc ConfigListString(common.v1.ConfigListQuery) returns (common.v1.ConfigStringList) {}

    rpc ConfigGetUint32(common.v1.ConfigKey) returns (common.v1.ConfigGetUint32Reply) {}
    rpc ConfigUpdateUint32(common.v1.ConfigUint32) returns (common.v1.ConfigUpdateReply) {}
    rpc ConfigListUint32(common.v1.ConfigListQuery) returns (common.v1.ConfigUint32List) {}

    rpc ConfigGetUint64(common.v1.ConfigKey) returns (common.v1.ConfigGetUint64Reply) {}
    rpc ConfigUpdateUint64(common.v1.ConfigUint64) returns (common.v1.ConfigUpdateReply) {}
    rpc ConfigListUint64(common.v1.ConfigListQuery) returns (common.v1.ConfigUint64List) {}

    // ----------------- DP INTERNAL RPCS -------------------------------
    // List all of the network connections which this node has with other dataplanes.
    // Established and un-established connections are shown. Users can drill down into
    // the individual connection to see its status.
    rpc ListConnections(ListConnectionsRequest) returns (ListConnectionsResponse) {}

    // Add new connections (for debugging purposes)
    rpc AddConnection(AddConnectionRequest) returns (AddConnectionResponse) {}

    // Remove new connections (for debugging purposes)
    rpc RemoveConnection(RemoveConnectionRequest) returns (RemoveConnectionResponse) {}

    // Sync the specified regions from the source deployment to the destination
    // deployment. Called by Symmetra.
    rpc SyncRegions(SyncRegionsRequest) returns (SyncRegionsResponse) {}

    // Return a hash list for the specified deployment, over the specified range.
    // Note: this is a streaming RPC as the hash lists returned could
    // conceiveably be multiple megabytes in size.
    //
    // returns the hash list and deployment hash
    rpc DeploymentHashList(DeploymentHashListRequest) returns (stream DeploymentHashListResponse) {}

    // Collect the dataplane node-level metrics and specific per-volume metrics.
    // NOTE: This is an experimental dataplane-only API. It's probably not quite
    // what the control-plane requires in terms of a metrics API, but it's fine
    // for dataplane tooling and tests.
    rpc Metrics(MetricsRequest) returns (MetricsResponse) {}
}

message StatusRequest {}

message StatusResponse {}

message ConfigureDeploymentRequest {
    DeploymentConfig config = 1;
}

message ConfigureDeploymentResponse {
    common.v1.RpcResult rpc_result = 1;
}

message DeconfigureDeploymentRequest {
    string uuid = 1;
}

message DeconfigureDeploymentResponse {
    common.v1.RpcResult rpc_result = 1;
}

message DeleteDeploymentRequest {
    string uuid = 1;
}

message DeleteDeploymentResponse {
    common.v1.RpcResult rpc_result = 1;
}

message ConfigurePresentationRequest {
    PresentationConfig config = 1;
}

message ConfigurePresentationResponse {
    common.v1.RpcResult rpc_result = 1;
    PresentationScsiDevice device_info = 2;
}

message DeconfigurePresentationRequest {
    string presentation_uuid = 1;
}

message DeconfigurePresentationResponse {
    common.v1.RpcResult rpc_result = 1;
}

message SetConsumerCountRequest {
    string uuid = 1;
    common.v1.ConsumerCount cc = 2;
}

message SetConsumerCountResponse {
    common.v1.RpcResult rpc_result = 1;
    common.v1.ConsumerCount cc = 2;
}

message GetConsumerCountRequest {
    string uuid = 1;
}

message GetConsumerCountResponse {
    common.v1.RpcResult rpc_result = 1;
    common.v1.ConsumerCount cc = 2;
}

message Snapshot {
    uint64 snapshot_id = 1;
}

message DumpConfigRequest {}

message DumpConfigResponse {
    // We declare a wrapper type so we can easily add new fields in the future
    message DeploymentConfigBundle {
        DeploymentConfig config = 1;
        repeated Snapshot snapshots = 2;
    }
    message PresentationConfigBundle { PresentationConfig config = 1; }

    map<string, DeploymentConfigBundle> deployments = 1;
    map<string, PresentationConfigBundle> presentations = 2;
    map<string, Connection> connections = 3;
}

message CreateSnapshotRequest {
    string deployment_uuid = 1;
    uint64 snapshot_id = 2;
}

message CreateSnapshotResponse {
    common.v1.RpcResult rpc_result = 1;
}

message ReapSnapshotRequest {
    string deployment_uuid = 1;
    uint64 snapshot_id = 2;
}

message ReapSnapshotResponse {
    common.v1.RpcResult rpc_result = 1;
}

message ListSnapshotsRequest {
    string deployment_uuid = 1;
}

message ListSnapshotsResponse {
    repeated Snapshot snapshots = 1;
}

// INTERNAL APIS ------------------------------------------------------------

/**
 ** Deployment hash lists (sync).
 **/

// Syncing a volume is a multi stage process:
//
// * first the CP invokes symmetra (a standalone binary), which then
// * calls the DeploymentHashList() RPC for the master and replica deployments
// * symmetra then calls the SyncRegions() RPC multiple times on the master to copy the
//   data
//
// We want to be able to track this transaction across it's entire duration.
// The SyncContext message type allows us to do this. When symmetra is first
// invoked it generates the SyncContext. This token is then passed in all
// subsequent DeploymentHashListRequests and SyncRegionRequests. Any code taking
// part in the sync operation can then log this ID as part of any structued
// logging calls.
//
// UUIDs seem to be in fashion at the moment so we'll use that as the unique
// identifier.
message SyncContext {
    string uuid = 1;
}

message DeploymentHash {
    // There's no way to define this in the proto but bytes.size() is always
    // sizeof(HashType_t). Currently 16 bytes.
    bytes bytes = 1;
}

// Note: the response to this message, DeploymentHashListResponse, is chunked
// (streamed in gRPC parlance).
message DeploymentHashListRequest {
    // The deployment UUID we want to generate a hash over.
    string deployment_uuid = 1;

    // Defines the byte offset into `deployment_uuid` at which we'll start hash list
    // generation.
    uint64 start_offset = 2;

    // Defines the byte offset into `deployment_uuid` at which we'll end hash list
    // generation.
    uint64 end_offset = 3;

    // When generating the hash list we do so by rolling together individual
    // block hashes into a region hash. This field defines the size of that
    // region in bytes. It must be multiple of RIXIO_BSIZE. By giving the option
    // for clients to specify this size they can optimise based on deployment size
    // and required sync granularity.
    uint64 region_size = 4;

    // This field is redundant (i.e it's ignored) as of release v2.5.0. We've
    // had to keep it in order that we don't break older builds which pin the
    // service repo to origin/main rather than an explicit commit. See a more
    // thorough explanation on the Sync RPC documentation in this file (DP-452).
    bool is_compressed = 5;

    // The SyncContext, initially generated by symmetra, associated with the
    // over-arching sync operation This field is purely used for logging, so
    // there's no harm in not setting it in test code
    SyncContext sync_context = 6;
}

// This message is streamed back to the client in response to a
// DeploymentHashListRequest message. As such the client should expect to receive
// many of these messages. Each DeploymentHashListResponse contains the hash list
// for a sequential portion of the deployment. For simplicity the deployment_hash -- i.e
// the hash for the range [start_offset, end_offset) as specified in the initial
// DeploymentHashListRequest
// -- is stored in every message.
message DeploymentHashListResponse {
    // The hash over the region [start_offset, end_offset) as specified in the
    // initial DeploymentHashListRequest
    DeploymentHash deployment_hash = 1;

    // Defines the byte offset into `deployment_uuid` at which hash_list[0] begins.
    uint64 start_offset = 2;

    // Defines the byte offset into `deployment_uuid` at which hash_list[max] ends.
    uint64 end_offset = 3;

    // A list of region hashes pertaining to the regions defined by the byte
    // range [start_offset, end_offset). The number of regions depends on the
    // `region_size` defined in the inital DeploymentHashListRequest.
    repeated DeploymentHash hash_list = 4;
}

/*
 * Metrics
 */
enum MetricType {
    // Counters may only increase (like an odometer)
    COUNT = 0;

    // Gauges may fluctuate (like a speedometer)
    GAUGE = 1;
}

message Metric {
    // The metric name
    string name = 1;

    // Counter or gauge
    MetricType type = 2;

    // Instantaneous value
    uint64 value = 3;
}

message MetricsRequest {
    // A list of volume to query (by uuid). If this and uuids is left empty
    // we'll return metrircs for all volumes which are configured.
    repeated string uuids = 1;
}

message VolumeMetrics {
    repeated Metric metrics = 1;
}

// Node-level metrics are metrics which aren't specific to a volume.
message NodeMetrics {
    repeated Metric metrics = 1;
}

message MetricsResponse {
    // Per volume stats. One collection of metrics per requested volume.
    map<string, VolumeMetrics> volume_metrics = 1;

    // Per node stats. One collection per node.
    NodeMetrics node_metrics = 2;
}

message ListConnectionsRequest {}

message Connection {
    // The remote peer's UUID
    string uuid = 1;

    // The hostname of the remote peer
    string hostname = 2;

    // The port of the remote peer normally 5703 (can be overriden by starting
    // the Dataplane with IO_BIND_PORT=<port>)
    uint32 port = 3;

    // Whether or not a connection is established with the remote peer
    bool connected = 4;
}

message ListConnectionsResponse {
    // A list of connections keyed by UUID. That's the only field we can
    // guarantee is unique. hostname need not be (for example in DP unit
    // test which spin up multiple dataplanes on the same node)
    map<string, Connection> connections = 1;
}

// Rpcs used for debugging
message AddConnectionRequest {
    NodeConfig config = 1;
}

message AddConnectionResponse {
    common.v1.RpcResult rpc_result = 1;
}

message RemoveConnectionRequest {
    NodeConfig config = 1;
}

message RemoveConnectionResponse {
    common.v1.RpcResult rpc_result = 1;
}

message SyncRegion {
    uint64 start_offset = 1;
    uint64 end_offset = 2;
}

message SyncRegionsRequest {
    // The source UUID.
    string source_uuid = 1;

    // The destination UUID.
    // This field is used as the volume identifier over destination_volume if
    // destination_volume is set to INVALID_INODE;
    string destination_uuid = 2;

    // The regions to sync
    repeated SyncRegion regions = 3;

    // Whether the sync should be forced. If this flag is set we'll overwrite
    // every sync block transaction ID with TransactionId{node_cc, 0}, where
    // node_cc is the consumer count of the source volume. See sync2020.pdf for
    // the rationale behind this.
    bool force = 4;

    // The SyncContext, initially generated by symmetra, associated with the
    // over-arching sync operation This field is purely used for logging, so
    // there's no harm in not setting it in test code
    SyncContext sync_context = 5;

    // If set we'll wait for the network connection between the sync source (the
    // master) and the sync target (the replica) to establish before trying to
    // sync any data. If the network connection never establishes then we'll
    // fail the operation. We'll wait for up to 1.5 times the directfs initiator
    // reconnection interval before giving up.
    //
    // This feature was added as a result of DP-280 and addresses the problem
    // where the CP configures the directfs initiator connection and starts the
    // sync operation before the connection is established. Something like this:
    // 1. CP configures connection from node A to node B
    // 2. Node B reboots
    // 3. Node A sits there in a retry loop trying to re-establish connection A
    // -> B,
    //    this happens every 5 seconds CP runs symmetra.
    // 4. The hash list generation succeeds on node A and node B in couple of
    // milliseconds
    // 5. Symmetra start's syncing data, and fails immediately as we still don't
    // have an
    //    established connection between A and B
    // 6. Eventually connection A -> B succeeds
    // 7. CP throws away the replica because the sync fails
    //
    // The intention is that this boolean will be set true for the first
    // SyncRegionsRequest sent by symmetra for a given sync operation. All
    // subsequent requests will set the boolean to false - we don't want to
    // stall the sync process by continually waiting for a flappy network.
    bool wait_for_connection_established = 6;
}

message SyncRegionsResponse {
    // Whether or not the operation was successful.
    bool success = 1;

    // If the operation was not successful, this is an explanatory message as to
    // why.
    string reason = 2;
}

// DEPRECATED post 2.5.0-ga see comment on SyncRegion RPC definition
message SyncRegionRequest {
    // The source volume ID.
    uint64 source_volume = 1;

    // The source UUID.
    // This field is used as the volume identifier over destination_volume if
    // destination_volume is set to INVALID_INODE;
    string source_uuid = 2;

    // The destination volume ID.
    uint64 destination_volume = 3;

    // The destination UUID.
    // This field is used as the volume identifier over destination_volume if
    // destination_volume is set to INVALID_INODE;
    string destination_uuid = 4;

    // The start offset.
    uint64 offset = 5;

    // The length of region to sync.
    uint64 length = 6;

    // Whether the sync should be forced. If this flag is set we'll overwrite
    // every sync block transaction ID with TransactionId{node_cc, 0}, where
    // node_cc is the consumer count of the source volume. See sync2020.pdf for
    // the rationale behind this.
    bool force = 7;

    // The SyncContext, initially generated by symmetra, associated with the
    // over-arching sync operation This field is purely used for logging, so
    // there's no harm in not setting it in test code
    SyncContext sync_context = 8;

    // If set we'll retry the write portion of a sync operation if it fails
    // because the directfs initiator has not established a connection to the
    // target node (the replica). We will do this for the first IO only.
    // Remember internally every SyncRegionRequest is broken down into multiple
    // 128k IOs. Any subsequent write failures due to a severed connection will
    // abort the sync process. The amount of time we'll wait before retrying
    // will always be greater than the cool-off period between connection
    // re-establish attempts. This is currently configured to 5 seconds.
    //
    // Note: symmetra should set this flag for the first SyncRegionRequest only.
    // The desired behaviour is that only the very first IO can elicit a retry.
    // We don't want per IO retries for sync operations.
    bool allow_first_io_retry = 9;
}

message SyncRegionResponse {
    // Whether or not the operation was successful.
    bool success = 1;

    // If the operation was not successful, this is an explanatory message as to
    // why.
    string reason = 2;
}
